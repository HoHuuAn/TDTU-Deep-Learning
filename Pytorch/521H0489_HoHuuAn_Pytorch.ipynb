{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Training on GPU\n",
      " NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available. Training on CPU')\n",
    "else:\n",
    "    print('CUDA is available! Training on GPU\\n', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transforms.ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "batchSize = 200\n",
    "\n",
    "trainset, validateset = random_split(dataset, [45000, 5000])\n",
    "\n",
    "train = DataLoader(trainset, batchSize, shuffle=True)\n",
    "validate = DataLoader(validateset, batchSize, shuffle=True)\n",
    "testLoader = DataLoader(testset, batch_size=batchSize, shuffle=False)\n",
    "\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define A Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4 * 4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def trainingStep(self, batch):\n",
    "        images, labels = batch\n",
    "\n",
    "        out = self(images)\n",
    "\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def accuracy(self, outputs, labels):\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "    def validationStep(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        accuracy = self.accuracy(out, labels)\n",
    "\n",
    "        return {\"loss\": loss, \"accuracy\": accuracy}\n",
    "\n",
    "    def validationEpochEnd(self, outputs):\n",
    "\n",
    "        batchLosses = [row[\"loss\"] for row in outputs]\n",
    "        epochLosses = torch.stack(batchLosses).mean()\n",
    "        batchAcc = [row[\"accuracy\"] for row in outputs]\n",
    "        epochAcc = torch.stack(batchAcc).mean()\n",
    "\n",
    "        return {\"loss\": epochLosses.item(), \"accuracy\": epochAcc.item()}\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluateModel(model, validationLoader):\n",
    "    model.eval()\n",
    "    out = [model.validationStep(batch) for batch in validationLoader]\n",
    "\n",
    "    return model.validationEpochEnd(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(epochs, lr, model, trainLoader, validationLoader, optimizationFunction=torch.optim.SGD):\n",
    "    optimizer = optimizationFunction(model.parameters(), lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"training epoch {epoch}\")\n",
    "        model.train()\n",
    "        trainingLosses = []\n",
    "\n",
    "        for batch in trainLoader:\n",
    "            loss = model.trainingStep(batch)\n",
    "            trainingLosses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print(f\"after training epoch {epoch} we get results {evaluateModel(model, validationLoader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 2.3029520511627197, 'accuracy': 0.09919998794794083}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Cifar10Classifier()\n",
    "evaluateModel(model, validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 0\n",
      "after training epoch 0 we get results {'loss': 1.3440661430358887, 'accuracy': 0.48680001497268677}\n",
      "training epoch 1\n",
      "after training epoch 1 we get results {'loss': 1.0307908058166504, 'accuracy': 0.6258000731468201}\n",
      "training epoch 2\n",
      "after training epoch 2 we get results {'loss': 0.836700975894928, 'accuracy': 0.7051999568939209}\n",
      "training epoch 3\n",
      "after training epoch 3 we get results {'loss': 0.7258360385894775, 'accuracy': 0.7504000067710876}\n",
      "training epoch 4\n",
      "after training epoch 4 we get results {'loss': 0.6655386090278625, 'accuracy': 0.763200044631958}\n",
      "training epoch 5\n",
      "after training epoch 5 we get results {'loss': 0.6501905918121338, 'accuracy': 0.7755999565124512}\n",
      "CPU times: total: 36min 10s\n",
      "Wall time: 15min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainModel(6, 0.001, model, trainLoader=train, validationLoader=validate, optimizationFunction=torch.optim.Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cifar10Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 0\n",
      "after training epoch 0 we get results {'loss': 1.6845744848251343, 'accuracy': 0.3628000020980835}\n",
      "training epoch 1\n",
      "after training epoch 1 we get results {'loss': 1.4758896827697754, 'accuracy': 0.44679996371269226}\n",
      "training epoch 2\n",
      "after training epoch 2 we get results {'loss': 1.4316095113754272, 'accuracy': 0.477400004863739}\n",
      "training epoch 3\n",
      "after training epoch 3 we get results {'loss': 1.3671494722366333, 'accuracy': 0.49880000948905945}\n",
      "training epoch 4\n",
      "after training epoch 4 we get results {'loss': 1.3041396141052246, 'accuracy': 0.5202000141143799}\n",
      "training epoch 5\n",
      "after training epoch 5 we get results {'loss': 1.2676283121109009, 'accuracy': 0.5356000065803528}\n",
      "CPU times: total: 12min 16s\n",
      "Wall time: 10min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainModel(6, 0.001, model, trainLoader=train, validationLoader=validate, optimizationFunction=torch.optim.Adagrad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cifar10Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 0\n",
      "after training epoch 0 we get results {'loss': 1.422218680381775, 'accuracy': 0.46459999680519104}\n",
      "training epoch 1\n",
      "after training epoch 1 we get results {'loss': 1.0822327136993408, 'accuracy': 0.6132000088691711}\n",
      "training epoch 2\n",
      "after training epoch 2 we get results {'loss': 0.9080066084861755, 'accuracy': 0.6833999752998352}\n",
      "training epoch 3\n",
      "after training epoch 3 we get results {'loss': 0.7564858198165894, 'accuracy': 0.7310000061988831}\n",
      "training epoch 4\n",
      "after training epoch 4 we get results {'loss': 0.7107223272323608, 'accuracy': 0.7539999485015869}\n",
      "training epoch 5\n",
      "after training epoch 5 we get results {'loss': 0.6667570471763611, 'accuracy': 0.781999945640564}\n",
      "CPU times: total: 17min 53s\n",
      "Wall time: 11min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainModel(6, 0.001, model, trainLoader=train, validationLoader=validate, optimizationFunction=torch.optim.AdamW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cifar10Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 0\n",
      "after training epoch 0 we get results {'loss': 2.3031013011932373, 'accuracy': 0.09940000623464584}\n",
      "training epoch 1\n",
      "after training epoch 1 we get results {'loss': 2.3030920028686523, 'accuracy': 0.09940000623464584}\n",
      "training epoch 2\n",
      "after training epoch 2 we get results {'loss': 2.3030834197998047, 'accuracy': 0.09940000623464584}\n",
      "training epoch 3\n",
      "after training epoch 3 we get results {'loss': 2.3030753135681152, 'accuracy': 0.09939999878406525}\n",
      "training epoch 4\n",
      "after training epoch 4 we get results {'loss': 2.3030667304992676, 'accuracy': 0.09940000623464584}\n",
      "training epoch 5\n",
      "after training epoch 5 we get results {'loss': 2.3030588626861572, 'accuracy': 0.09940000623464584}\n",
      "CPU times: total: 4min 57s\n",
      "Wall time: 9min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainModel(6, 0.001, model, trainLoader=train, validationLoader=validate, optimizationFunction=torch.optim.Adadelta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cifar10Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 0\n",
      "after training epoch 0 we get results {'loss': 1.48053777217865, 'accuracy': 0.43880000710487366}\n",
      "training epoch 1\n",
      "after training epoch 1 we get results {'loss': 1.3311346769332886, 'accuracy': 0.5192000269889832}\n",
      "training epoch 2\n",
      "after training epoch 2 we get results {'loss': 1.1267459392547607, 'accuracy': 0.587399959564209}\n",
      "training epoch 3\n",
      "after training epoch 3 we get results {'loss': 1.0351043939590454, 'accuracy': 0.6294000148773193}\n",
      "training epoch 4\n",
      "after training epoch 4 we get results {'loss': 0.9445332288742065, 'accuracy': 0.6580000519752502}\n",
      "training epoch 5\n",
      "after training epoch 5 we get results {'loss': 0.8266209363937378, 'accuracy': 0.7071999907493591}\n",
      "CPU times: total: 18min 23s\n",
      "Wall time: 12min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainModel(6, 0.001, model, trainLoader=train, validationLoader=validate, optimizationFunction=torch.optim.Adamax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer ASGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cifar10Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 0\n",
      "after training epoch 0 we get results {'loss': 2.3031508922576904, 'accuracy': 0.0965999960899353}\n",
      "training epoch 1\n",
      "after training epoch 1 we get results {'loss': 2.3031275272369385, 'accuracy': 0.0965999960899353}\n",
      "training epoch 2\n",
      "after training epoch 2 we get results {'loss': 2.303105354309082, 'accuracy': 0.0965999960899353}\n",
      "training epoch 3\n",
      "after training epoch 3 we get results {'loss': 2.3030846118927, 'accuracy': 0.0965999960899353}\n",
      "training epoch 4\n",
      "after training epoch 4 we get results {'loss': 2.303065538406372, 'accuracy': 0.0965999960899353}\n",
      "training epoch 5\n",
      "after training epoch 5 we get results {'loss': 2.303046941757202, 'accuracy': 0.0966000109910965}\n",
      "CPU times: total: 2h 47min 50s\n",
      "Wall time: 37min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainModel(6, 0.001, model, trainLoader=train, validationLoader=validate, optimizationFunction=torch.optim.ASGD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
